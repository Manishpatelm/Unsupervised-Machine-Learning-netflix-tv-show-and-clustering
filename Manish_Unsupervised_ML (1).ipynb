{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "QHF8YVU7Yuh3",
        "gIfDvo9L0UH2"
      ],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - ***NETFLIX MOVIE AND TV SHOW CLUSTERING***\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised Machine Learning\n",
        "##### **Contribution**    - Individual\n",
        "##### **Project by**      - Manish Patel"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix, founded in 1997 by Marc Randolph and Reed Hastings, is the world's largest on-demand internet streaming media and online DVD movie rental service provider. With over 69 million members in more than 60 countries, Netflix users enjoy more than 100 million hours of TV shows and movies every day.\n",
        "\n",
        "A dataset collected from Fixable, a third-party Netflix search engine, contains information on the content available on the platform as of 2019. According to a report by Fixable, the number of TV shows on Netflix has nearly tripled since 2010, while the number of movies has decreased by more than 2,000 titles. By analyzing this dataset, one can uncover interesting insights about the content available on Netflix. Integrating this dataset with external sources such as IMDB ratings and Rotten Tomatoes can also provide additional valuable information."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Manishpatelm/Unsupervised-Machine-Learning-netflix-tv-show-and-clustering/upload/main"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains information on movies and TV shows that were available on Netflix in 2019, sourced from a third-party Netflix search engine called Flixable. The dataset provides an opportunity to investigate the changes in the content available on Netflix over time, particularly the shift in the number of TV shows versus movies.\n",
        "\n",
        "According to a report from 2018, the number of TV shows on Netflix had grown significantly since 2010, while the number of movies had decreased by over 2,000 titles. By analyzing this dataset, we can uncover more insights into this trend and potentially discover other interesting findings by integrating it with external datasets, such as ratings from IMDB or Rotten Tomatoes."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from matplotlib.pyplot import figure\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "from datetime import datetime as dt\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import re, string, unicodedata\n",
        "\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "string.punctuation\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "t5qEbvxA-wRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data using exception handling\n",
        "\n",
        "try:\n",
        "  # Load Dataset\n",
        "  file_path= '/content/drive/MyDrive/ almabetter csv file/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "  df=pd.read_csv(file_path)\n",
        "except FileNotFoundError:\n",
        "  print('Please provide correct file path for csv data')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Last Look\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "zaNs2scu_OQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df[df.duplicated()]"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "no duplicated value in dataset."
      ],
      "metadata": {
        "id": "r0JSzouxHGtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Checking Null Value by plotting Heatmap\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.heatmap(df.isnull(), cbar=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In that dataset this column null value there 1. director=2389,cast =718,country=507,date_added=10"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#total null values\n",
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling the missing values\n",
        "df[['director','cast','country']] = df[['director','cast','country']].fillna('Unknown')\n",
        "df['rating'] = df['rating'].fillna(df['rating'].mode()[0])\n",
        "df.dropna(axis=0, inplace = True)"
      ],
      "metadata": {
        "id": "B77j9RGRt6j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#again checking is there any null values are not\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "uiclCdmRuBZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "eO-nzoSnuQ_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SG0HLwiXuvGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *** Feature Engineering***"
      ],
      "metadata": {
        "id": "rBQ81n4suxEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top countries\n",
        "df.country.value_counts()"
      ],
      "metadata": {
        "id": "8mmgsYz7u4Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Genre of shows\n",
        "df.listed_in.value_counts()"
      ],
      "metadata": {
        "id": "li6-x_s6vBph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing the primary country and primary genre to simplify the analysis\n",
        "df['country'] = df['country'].apply(lambda x: x.split(',')[0])\n",
        "df['listed_in'] = df['listed_in'].apply(lambda x: x.split(',')[0])"
      ],
      "metadata": {
        "id": "4tIFKqhAvFBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contry in which a movie was produced\n",
        "df.country.value_counts()"
      ],
      "metadata": {
        "id": "kvAz-QZTvII0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genre of shows\n",
        "df.listed_in.value_counts()"
      ],
      "metadata": {
        "id": "u9uUUxVuvOyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the duration column, and changing the datatype to integer\n",
        "df['duration'] = df['duration'].apply(lambda x: int(x.split()[0]))"
      ],
      "metadata": {
        "id": "PFLc8vcnvTQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of seasons for tv shows\n",
        "df[df['type']=='TV Show'].duration.value_counts()"
      ],
      "metadata": {
        "id": "5e5Asq-zvXPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Movie length in minutes\n",
        "df[df['type']=='Movie'].duration.unique()"
      ],
      "metadata": {
        "id": "ROJnv1K-vayq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Date_added column string to Datetime format"
      ],
      "metadata": {
        "id": "2qeWY5cevj8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Typecasting 'date_added' from string to datetime\n",
        "df['date_added '] = pd.to_datetime(df['date_added'])"
      ],
      "metadata": {
        "id": "uWWD7DDYv0NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')"
      ],
      "metadata": {
        "id": "Sae-BHvxv8WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first and last date on which a show was added on Netflix\n",
        "df.date_added.min(),df.date_added.max()"
      ],
      "metadata": {
        "id": "c53kWMlXwBAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding new attributes month and year of date added\n",
        "\n",
        "df['month_added'] = df['date_added'].dt.month\n",
        "df['year_added'] = df['date_added'].dt.year\n",
        "df.drop('date_added', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "NWvTLRAJxdrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "XYr_f3fLxsij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "lpkdrVTSxxkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we handale thew missing value of country director and cast and change date data types object to datetime."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 Number of Movies and TV Shows in the dataset"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(7,7))\n",
        "df.type.value_counts().plot(kind='pie',autopct='%1.2f%%')\n",
        "plt.ylabel('')\n",
        "plt.title('Movies and TV Shows in the dataset')"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie charts are generally used to show the proportions of a whole, and are especially useful for displaying data that has already been calculated as a percentage of the whole."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this dataset 69.14% is movie and 30.86% TV Show."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The business can consider focusing on producing high-quality movies to cater to the audience demand."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 Top 10 directors in the dataset"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown')].director.value_counts().nlargest(10).plot(kind='bar')\n",
        "plt.title('Top 10 directors by number of shows directed')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots are a type of data visualization used to represent data in the form of rectangular bars. The height of each bar represents the value of a data point, and the width of each bar represents the category of the data."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Raul Campos Jan Suter made highest movie."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Raul Campos Jan Suter, marcus Raboy and  Jay Karas  made most movie they are experience."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Chart - 3 Top 10 countries with the highest number movies / TV shows in the dataset**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['country']=='Unknown')].country.value_counts().nlargest(10).plot(kind='bar')\n",
        "plt.title(' Top 10 countries with the highest number of shows')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar plot shows catergorical data as rectangular bars with the height of bars proportional to the value they represent."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.united States are the top one country of highest number movies / TV shows in the dataset.\n",
        "\n",
        "2.Australia are the top 10 lowest number movies / TV shows in the dataset"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see in USA highest movies and TV show making according to that we marketing thingth."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 Visualizing the year in which the movie / tv show was released"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Visualizing the year in which the movie / tv show was released\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df['release_year'])\n",
        "plt.title('distribution by released year')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In statistics, a histogram is a graphical representation of the distribution of data. The histogram is represented by a set of rectangles, adjacent to each other, where each bar represent a kind of data."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "n this histogram we found release_year 2000 to 2020 more the the movie / tv show was released"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this dataset most of the movie/ tv shows made in year 2000 to 2020."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 Length distribution of movies"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "movie_df = df[df['type']=='Movie']\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "sns.distplot(movie_df['duration'], bins=30,color='Blue').set(ylabel=None)\n",
        "\n",
        "plt.title('Length distribution of movies', fontsize=16,fontweight=\"bold\")\n",
        "plt.xlabel('Duration', fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this plot we found the Length distribution of most of the  movies duration is 50 to 150 ."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "most of the movies time duration is 50 min to 150 min.and more than 150 min movie became boring ."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 Age ratings for shows in the dataset"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(x='rating',data=df)"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "countplot() method is used to Show the counts of observations in each categorical bin using bars."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " in this plot we found all rating count. TV-MA is the highest rating and second highest is TV-14 and third highest is TV-PG rating."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TV-MA  is highest rating point. we should more focused on TV-MA"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the values in the rating column\n",
        "rating_map = {'TV-MA':'Adults',\n",
        "              'R':'Adults',\n",
        "              'PG-13':'Teens',\n",
        "              'TV-14':'Young Adults',\n",
        "              'TV-PG':'Older Kids',\n",
        "              'NR':'Adults',\n",
        "              'TV-G':'Kids',\n",
        "              'TV-Y':'Kids',\n",
        "              'TV-Y7':'Older Kids',\n",
        "              'PG':'Older Kids',\n",
        "              'G':'Kids',\n",
        "              'NC-17':'Adults',\n",
        "              'TV-Y7-FV':'Older Kids',\n",
        "              'UR':'Adults'}\n",
        "\n",
        "df['rating'].replace(rating_map, inplace = True)\n",
        "df['rating'].unique()"
      ],
      "metadata": {
        "id": "qeruFWyWHGoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['principal_country'] = df['country'].apply(lambda x: x.split(\",\")[0])\n",
        "df['principal_country'].head()\n",
        "\n",
        "country_order = df['principal_country'].value_counts()[:11].index\n",
        "content_data = df[['type', 'principal_country']].groupby('principal_country')['type'].value_counts().unstack().loc[country_order]\n",
        "content_data['sum'] = content_data.sum(axis=1)\n",
        "content_data_ratio = (content_data.T / content_data['sum']).T[['Movie', 'TV Show']].sort_values(by='Movie',ascending=False)[::-1]"
      ],
      "metadata": {
        "id": "9ua0pmpkHTtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['count'] = 1\n",
        "data = df.groupby('principal_country')[['principal_country','count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "data = data['principal_country']\n",
        "\n",
        "Flix_df_heatmap = df.loc[df['principal_country'].isin(data)]\n",
        "Flix_df_heatmap = pd.crosstab(Flix_df_heatmap['principal_country'], Flix_df_heatmap['rating'],normalize = \"index\").T\n",
        "Flix_df_heatmap"
      ],
      "metadata": {
        "id": "C_uqps34HbTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 Age ratings for shows in the dataset"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(x='rating',data=df)\n",
        "plt.title('Number of shows on Netflix for different age groups')"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Countplot() method is used to Show the counts of observations in each categorical bin using bars."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this count plot we found that Number of shows on Netflix for different age groups and Adults are the highest number of shows and second highest is Young Adults and third highest is older Kids shows."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we shuold focus more on adult types customers."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 Top 10 genres"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "df.listed_in.value_counts().nlargest(10).plot(kind='bar')\n",
        "plt.title('Top 10 genres')"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar graph is a graphical representation of data in which we can highlight the category with particular shapes like a rectangle. The length and heights of the bar chart represent the data distributed in the dataset. In a bar chart, we have one axis representing a particular category of a column in the dataset and another axis representing the values or counts associated with it. Bar charts can be plotted vertically or horizontally. A vertical bar chart is often called a column chart."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this bar plot we found Dramas are large value_counts of shows and movies and Comedies are the second large value_counts of shows and Movies."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we should more focused on dramas and comedy type movie."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 Number of movies and TV shows added over the years"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "p = sns.countplot(x='year_added',data=df, hue='type')\n",
        "plt.title('Number of movies and TV shows added over the years')\n",
        "plt.xlabel('')\n",
        "for i in p.patches:\n",
        "  p.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " A bivariate plot graphs the relationship between two variables that have been measured on a single sample of subjects. Such a plot permits you to see at a glance the degree and pattern of relation between the two variables."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this graph we found that Number of movies and TV shows added over the years.2019 are the 1497 movies and 656 TV shows are there. 2020 year 1312 movies and 697 TV shows are there and 2018 year 1255 movies and 430 TV shows are there."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in every year more movie produces comare to TV show."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 Top 10 genre for movies"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "df[df['type']=='TV Show'].listed_in.value_counts().nlargest(10).plot(kind='bar')\n",
        "plt.title('Top 10 genres for movies')"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar plot shows catergorical data as rectangular bars with the height of bars proportional to the value they represent. It is often used to compare between values of different categories in the data."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this graph we found Top 10 genres for movies. International TV Shows are the highest number of genres type of TV shows and Crime TVShows and Kid's Shows are approximately same for generes type of TV shows."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here internation TV show is very popular."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
        "country_order2 = ['United States', 'India', 'United Kingdom', 'Canada', 'Japan', 'France', 'South Korea', 'Spain',\n",
        "       'Mexico']\n",
        "\n",
        "age_order = ['Adults', 'Teens', 'Young Adults', 'Older Kids', 'Kids']\n",
        "\n",
        "sns.heatmap(Flix_df_heatmap.loc[age_order,country_order2],cmap=\"jet\",square=True, linewidth=2.5,cbar=False,\n",
        "            annot=True,fmt='2.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={\"fontsize\":15})\n",
        "\n",
        "ax.spines['top'].set_visible(True)\n",
        "\n",
        "fig.text(.76,.765, 'Target ages proportion of total content by country', fontweight='bold', fontfamily='serif', fontsize=15,ha='right')\n",
        "\n",
        "ax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=11)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), fontfamily='serif', rotation=90, fontsize=11)\n",
        "\n",
        "ax.set_ylabel('')\n",
        "ax.set_xlabel('')\n",
        "ax.tick_params(axis=u'both', which=u'both',length=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i. A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. A correlation matrix is used to summarize data, as an input into a more advanced analysis, and as a diagnostic for advanced analyses. The range of correlation is [-1,1].\n",
        "\n",
        "ii. Thus to know the correlation between all the variables along with the correlation coefficients, i used correlation heatmap.\n",
        "\n",
        "iii. In this correlation Heatmap graph we found the Target ages proportion of total content by country."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the original dataset for clustering since\n",
        "# it does not require handling missing values\n",
        "Dataset = df.copy()"
      ],
      "metadata": {
        "id": "RVZKt480XOHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset.fillna('',inplace=True)"
      ],
      "metadata": {
        "id": "F5TwggR1X4u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining all the clustering attributes into a single column\n",
        "\n",
        "Dataset['clustering'] = (Dataset['director'] + ' ' +\n",
        "                                Dataset['cast'] +' ' +\n",
        "                                Dataset['country'] +' ' +\n",
        "                                Dataset['listed_in'] +' ' +\n",
        "                                Dataset['description'])"
      ],
      "metadata": {
        "id": "ZoMp7LjXX8Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the 100 number of clusters for the dataset\n",
        "Dataset['clustering'][100]"
      ],
      "metadata": {
        "id": "9sm4YPMFX_tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Removing Punctuation**"
      ],
      "metadata": {
        "id": "7-MWc1D0YKne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove punctuations\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "lDRTcyWDYOgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing punctuation marks\n",
        "Dataset['clustering'] = Dataset['clustering'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "hydylLSqYsVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the 100 number of clusters for the dataset\n",
        "Dataset['clustering'][100]"
      ],
      "metadata": {
        "id": "IxBuIAsOYyBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Removing non-ASCII characters:**"
      ],
      "metadata": {
        "id": "g44selKhY6Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove non-ascii characters\n",
        "\n",
        "def remove_non_ascii(words):\n",
        "    \"\"\"Function to remove non-ASCII characters\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "uHc6J988Y9Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove non-ascii characters\n",
        "Dataset['clustering'] = remove_non_ascii(Dataset['clustering'])"
      ],
      "metadata": {
        "id": "7vUbQ2PKY9BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the 100 number of clusters for the dataset\n",
        "Dataset['clustering'][100]"
      ],
      "metadata": {
        "id": "28FlunHVZJ-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Removing stopwords**"
      ],
      "metadata": {
        "id": "9hIeXDeVZQ3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the stopwords from nltk library\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "sentences = stopwords.words('english')\n",
        "# displaying the stopwords\n",
        "np.array(sentences)"
      ],
      "metadata": {
        "id": "YfWDABe0ZUPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove stop words\n",
        "def remove_stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sentences]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "JGiTEZQrZa5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stop words\n",
        "Dataset['clustering'] = Dataset['clustering'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "cHJMnVKgZeFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the 100 number of clusters for the dataset\n",
        "Dataset['clustering'][100]"
      ],
      "metadata": {
        "id": "EIle2uWqZULC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Removing  Lemmatization:**"
      ],
      "metadata": {
        "id": "6WPwUajKZl1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to lemmatize the corpus\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas"
      ],
      "metadata": {
        "id": "0i5O_f2AZo3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "Dataset['clustering'] = lemmatize_verbs(Dataset['clustering'])"
      ],
      "metadata": {
        "id": "qX59OD3pZoyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the 100 number of clusters for the dataset\n",
        "print(Dataset['clustering'][100])"
      ],
      "metadata": {
        "id": "zLreh3TIZoou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenization:**"
      ],
      "metadata": {
        "id": "XRLiffMraTIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a reference variable for Class TweetTokenizer\n",
        "tokenizer = TweetTokenizer()"
      ],
      "metadata": {
        "id": "SsrXhxIpaVbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text column based on dataset\n",
        "Dataset['clustering'] = Dataset['clustering'].apply(lambda x: tokenizer.tokenize(x))"
      ],
      "metadata": {
        "id": "nvC4gS0Habjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the 100 number of Tokenization for the dataset\n",
        "print(Dataset['clustering'][100])"
      ],
      "metadata": {
        "id": "Fof7s5kPaeZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Vectorization:**"
      ],
      "metadata": {
        "id": "dN2ILyVkaq2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clustering tokens saved in a variable\n",
        "clustering_vectorization = Dataset['clustering']"
      ],
      "metadata": {
        "id": "4oOM5ZMMavY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "def tokenizer(text):\n",
        "  return text\n",
        "\n",
        "# Using TFIDF vectorizer to vectorize the corpus\n",
        "# max features = 20000 to prevent system from crashing\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizer, stop_words='english', lowercase=False,max_features = 20000)\n",
        "x = tfidf.fit_transform(clustering_vectorization)"
      ],
      "metadata": {
        "id": "XK-tm8ELaz9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "x.shape"
      ],
      "metadata": {
        "id": "4eU8XejUa46L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert X into array form for clustering\n",
        "X = x.toarray()"
      ],
      "metadata": {
        "id": "psFx80GSa4z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the matrix\n",
        "X"
      ],
      "metadata": {
        "id": "RK7tPHtCa_nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Reduceing Diemensionality using PCA**"
      ],
      "metadata": {
        "id": "5wgAUiO8bHbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using PCA to reduce dimensionality\n",
        "pca = PCA(random_state=40)\n",
        "pca.fit(X)"
      ],
      "metadata": {
        "id": "ZH79mEjwbKm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explained variance for different number of components\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title('PCA - Cumulative explained variance vs number of components')\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')"
      ],
      "metadata": {
        "id": "aOsQA_v8bKgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reducing the dimensions to 4000 using pca\n",
        "pca = PCA(n_components=4000,random_state=40)\n",
        "pca.fit(X)"
      ],
      "metadata": {
        "id": "o0I36MOsbKa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformed features\n",
        "x_pca = pca.transform(X)"
      ],
      "metadata": {
        "id": "Web2EUTxbXEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of transformed vectors\n",
        "x_pca.shape"
      ],
      "metadata": {
        "id": "zu8XnDYwbW0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Now start wih Unservised Machine Learning clustering algorithms**"
      ],
      "metadata": {
        "id": "vs9ELNhSbr5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1.K-Means Clustering:**"
      ],
      "metadata": {
        "id": "6U0qhVJdbwse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow method to find the optimal value of k\n",
        "wcss=[]\n",
        "for i in range(1,31):\n",
        "  kmeans = KMeans(n_clusters=i,init='k-means++',random_state=33)\n",
        "  kmeans.fit(x_pca)\n",
        "  wcss_iter = kmeans.inertia_\n",
        "  wcss.append(wcss_iter)\n",
        "\n",
        "number_clusters = range(1,31)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(number_clusters,wcss)\n",
        "plt.title('The Elbow Method - KMeans clustering')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')"
      ],
      "metadata": {
        "id": "D9dHdxLChzzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Silhouette score for different umber of clusters\n",
        "range_n_clusters = range(2,31)\n",
        "silhouette_avg = []\n",
        "for num_clusters in range_n_clusters:\n",
        "  # initialize kmeans\n",
        "  kmeans = KMeans(n_clusters=num_clusters,init='k-means++',random_state=33)\n",
        "  kmeans.fit(x_pca)\n",
        "  cluster_labels = kmeans.labels_\n",
        "\n",
        "  # silhouette score\n",
        "  silhouette_avg.append(silhouette_score(x_pca, cluster_labels))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(range_n_clusters,silhouette_avg)\n",
        "plt.xlabel('Values of K')\n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette analysis For Optimal k - KMeans clustering')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YKB40B02hztK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the data into 19 clusters\n",
        "kmeans = KMeans(n_clusters=6,init='k-means++',random_state=40)\n",
        "kmeans.fit(x_pca)"
      ],
      "metadata": {
        "id": "XojocV_hhzmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "Dataset['kmeans_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "ZZhSDsCehzed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics - distortion, Silhouette score\n",
        "kmeans_distortion = kmeans.inertia_\n",
        "kmeans_silhouette_score = silhouette_score(x_pca, kmeans.labels_)\n",
        "\n",
        "print((kmeans_distortion,kmeans_silhouette_score))"
      ],
      "metadata": {
        "id": "-Rh7InDxhzX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "q = sns.countplot(x='kmeans_cluster',data=Dataset, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
        "for i in q.patches:\n",
        "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ],
      "metadata": {
        "id": "FEn-OYaghzQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "def kmeans_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in Dataset[Dataset['kmeans_cluster']==cluster_num].description.values:\n",
        "\n",
        "      # typecaste each val to string\n",
        "      val = str(val)\n",
        "\n",
        "      # split the value\n",
        "      tokens = val.split()\n",
        "\n",
        "      # Converts each token into lowercase\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  wordcloud = WordCloud(width = 700, height = 700,\n",
        "                  background_color ='white',\n",
        "                  stopwords = stopwords,\n",
        "                  min_font_size = 10).generate(comment_words)"
      ],
      "metadata": {
        "id": "RPd-bDsphzJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "comment_words = ''\n",
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "# iterate through the csv file\n",
        "for val in df.description.values:\n",
        "\n",
        "    # typecaste each val to string\n",
        "    val = str(val)\n",
        "\n",
        "    # split the value\n",
        "    tokens = val.split()\n",
        "\n",
        "    # Converts each token into lowercase\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "\n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "wordcloud = WordCloud(width = 700, height = 700,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        "\n",
        "\n",
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (10,5), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "0NKa9_krWFmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,5), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "0kJyiq5VhzCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2.Hierarchical clustering:**"
      ],
      "metadata": {
        "id": "vVhBdimWilL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a dendogram to decide on the number of clusters\n",
        "plt.figure(figsize=(16, 7))\n",
        "dend = shc.dendrogram(shc.linkage(x_pca, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Netflix Shows')\n",
        "plt.ylabel('Distance')\n",
        "plt.axhline(y= 3.8, color='r', linestyle='--')"
      ],
      "metadata": {
        "id": "gKpgxGNGhy7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering model\n",
        "hierarchical = AgglomerativeClustering(n_clusters=12, affinity='euclidean', linkage='ward')\n",
        "hierarchical.fit_predict(x_pca)"
      ],
      "metadata": {
        "id": "vvp-0rR3hy0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "Dataset['hierarchical_cluster'] = hierarchical.labels_"
      ],
      "metadata": {
        "id": "ia4X5tlThyvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "q = sns.countplot(x='hierarchical_cluster',data=Dataset, hue='type')\n",
        "plt.title('Number of movies and tv shows in each cluster - Hierarchical Clustering')\n",
        "for i in q.patches:\n",
        "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ],
      "metadata": {
        "id": "69OteQ-FbyHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "def hierarchical_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in Dataset[Dataset['hierarchical_cluster']==cluster_num].description.values:\n",
        "\n",
        "      # typecaste each val to string\n",
        "      val = str(val)\n",
        "\n",
        "      # split the value\n",
        "      tokens = val.split()\n",
        "\n",
        "      # Converts each token into lowercase\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  wordcloud = WordCloud(width = 700, height = 700,\n",
        "                  background_color ='white',\n",
        "                  stopwords = stopwords,\n",
        "                  min_font_size = 10).generate(comment_words)\n",
        "  return hierarchical_worldcloud"
      ],
      "metadata": {
        "id": "51MxSH0Yi6Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # plot the WordCloud image\n",
        "plt.figure(figsize = (10,5), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "wqSeUUCfi-BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Content based recommender system**"
      ],
      "metadata": {
        "id": "atdRu0-QjJqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the index of the df from show id to show title\n",
        "Dataset['show_id'] = Dataset.index"
      ],
      "metadata": {
        "id": "wX0qbBpIjEIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting tokens to string\n",
        "def convert(lst):\n",
        "  return ' '.join(lst)\n",
        "\n",
        "Dataset['clustering'] = Dataset['clustering'].apply(lambda x: convert(x))"
      ],
      "metadata": {
        "id": "Nfm11g63jEBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting title of movies/Tv shows as index\n",
        "Dataset.set_index('title',inplace=True)"
      ],
      "metadata": {
        "id": "nR5h0fujjD8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count vectorizer\n",
        "CV = CountVectorizer()\n",
        "converted_matrix = CV.fit_transform(Dataset['clustering'])"
      ],
      "metadata": {
        "id": "uvNV1pFpjvxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine similarity\n",
        "cosine_similarity = cosine_similarity(converted_matrix)"
      ],
      "metadata": {
        "id": "PLyNlY5MjzEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "cosine_similarity.shape"
      ],
      "metadata": {
        "id": "a9gHn6_4j1wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Developing a function to get 10 recommendations for a show\n",
        "indices = pd.Series(Dataset.index)\n",
        "\n",
        "def Dataset_10(title, cosine_sim = cosine_similarity):\n",
        "  try:\n",
        "    recommend_content = []\n",
        "    idx = indices[indices == title].index[0]\n",
        "    series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
        "    top10 = list(series.iloc[1:11].index)\n",
        "    # list with the titles of the best 10 matching movies\n",
        "    for i in top10:\n",
        "      recommend_content.append(list(Dataset.index)[i])\n",
        "    print(\"If you liked '\"+title+\"', you may also enjoy:\\n\")\n",
        "    return recommend_content\n",
        "\n",
        "  except:\n",
        "    return 'Invalid Entry'"
      ],
      "metadata": {
        "id": "tqJ7SDHdj43i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'A Man Called God'\n",
        "Dataset_10('A Man Called God')"
      ],
      "metadata": {
        "id": "VPXLnaZCj75w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'Peaky Blinders'\n",
        "Dataset_10('Peaky Blinders')"
      ],
      "metadata": {
        "id": "ojVvO2Oqj88h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'Stranger Things'\n",
        "Dataset_10('Stranger Things')"
      ],
      "metadata": {
        "id": "KwiPRdtLj70T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here.\n",
        "\n",
        "1.In this project, we worked on a text clustering problem where in we had to classify/group the Netflix shows into certain clusters such that the shows within a cluster are similar to each other and the shows in different clusters are dissimilar to each other.\n",
        "\n",
        "\n",
        "2.The dataset contained about 7787 records, and 12 attributes.\n",
        "We began by dealing with the dataset's missing values and doing exploratory data analysis (EDA).\n",
        "\n",
        "\n",
        "3.It was found that Netflix hosts more movies than TV shows on its platform, and the total number of shows added on Netflix is growing exponentially. Also, majority of the shows were produced in the United States, and the majority of the shows on Netflix were created for adults and young adults age group.\n",
        "\n",
        "4.Once obtained the required insights from the EDA, we start with Pre-processing the text data by removing the punctuation, and, stop words. This filtered data is passed through TF - IDF Vectorizer since we are conducting a text-based clustering and the model needs the data to be vectorized in order to predict the desired results.\n",
        "\n",
        "\n",
        "5.It was decided to cluster the data based on the attributes: director, cast, country, genre, and description. The values in these attributes were tokenized, preprocessed, and then vectorized using TFIDF vectorizer.\n",
        "\n",
        "\n",
        "6.Through TFIDF Vectorization, we created a total of 20000 attributes.\n",
        "We used Principal Component Analysis (PCA) to handle the curse of dimensionality. 4000 components were able to capture more than 80% of variance, and hence, the number of components were restricted to 4000.\n",
        "We first built clusters using the k-means clustering algorithm, and the optimal number of clusters came out to be 6. This was obtained through the elbow method and Silhouette score analysis.\n",
        "\n",
        "\n",
        "7.Then clusters were built using the Agglomerative clustering algorithm, and the optimal number of clusters came out to be 12. This was obtained after visualizing the dendrogram.\n",
        "\n",
        "\n",
        "8.A content based recommender system was built using the similarity matrix obtained after using cosine similarity. This recommender system will make 10 recommendations to the user based on the type of show they watched."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}